{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4XIQtd-lZv5"
   },
   "source": [
    "# What is the purpose of Supervised Learning Regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "**Supervised Learning is a type Machine Learning where the model is trained on labeled data (that means the model sees also the corresponding outputs with inputs) and then it makes output predictions from unseen inputs.** </br>\n",
    "\n",
    "You can imagine it in the following way, the model will learn from data that looks like this: X --> Y (the arrow is mapping from X to Y)\n",
    "The model learn the mapping, what should he add, substract or so on with every input. And finally when it gets new input X, it will used the taught mapping (the arrow -->) and will predict X --> Y. </br>\n",
    "\n",
    "**There are two types of Supervised Learning: Regression and Classification, today we will look at the first one - Regression.\n",
    "Regression algorithms predict a number of infinitely possible outputs.** </br>\n",
    "\n",
    "For example you have this graph with housing price predictions, on the x-axis is the house size on the y-axis is the house price. Model learned the mapping what operations should it do to get output from any new input. And when it gets input it will simply give us the exact output price. </br>\n",
    "\n",
    "### Real World Use Cases of Supervised Learning Regression Algorithms\n",
    "**algorithm determines what should that arrow do with input**\n",
    "\n",
    "House ---> Prices based on properties that house has </br>\n",
    "Factory ---> Demand of input Products based on production and sales </br>\n",
    "Self-driving cars ---> The speed that car should drive based of external factors </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Zx0RdFGlZsZ"
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imrrABVvlZlR"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     car brand   model  generation_name  year  mileage  vol_engine      fuel  \\\n",
      "0         opel   combo       gen-d-2011  2015   139568        1248    Diesel   \n",
      "1         opel   combo       gen-d-2011  2018    31991        1499    Diesel   \n",
      "2         opel   combo       gen-d-2011  2015   278437        1598    Diesel   \n",
      "3         opel   combo       gen-d-2011  2016    47600        1248    Diesel   \n",
      "4         opel   combo       gen-d-2011  2014   103000        1400       CNG   \n",
      "...        ...     ...              ...   ...      ...         ...       ...   \n",
      "3099      opel  vectra  gen-c-2002-2008  2007   248000        1796  Gasoline   \n",
      "3100      opel  vectra  gen-c-2002-2008  2003   263000        1796       LPG   \n",
      "3101      opel  vectra  gen-c-2002-2008  2008   200000        1796  Gasoline   \n",
      "3102      opel  vectra  gen-c-2002-2008  2005   148266        1910    Diesel   \n",
      "3103      opel  vectra  gen-c-2002-2008  2007   182000        1796  Gasoline   \n",
      "\n",
      "                 city       province  price (PLN)  \n",
      "0               Janki    Mazowieckie        35900  \n",
      "1            Katowice        Śląskie        78501  \n",
      "2               Brzeg       Opolskie        27000  \n",
      "3           Korfantów       Opolskie        30800  \n",
      "4     Tarnowskie Góry        Śląskie        35900  \n",
      "...               ...            ...          ...  \n",
      "3099         Oleśnica   Dolnośląskie        13900  \n",
      "3100         Swarzędz  Wielkopolskie         7999  \n",
      "3101         Oleśnica   Dolnośląskie        14900  \n",
      "3102  Czarna Dąbrówka      Pomorskie        13000  \n",
      "3103         Jarosław   Podkarpackie        14900  \n",
      "\n",
      "[3104 rows x 10 columns]\n",
      "Index(['car brand', 'model', 'generation_name', 'year', 'mileage',\n",
      "       'vol_engine', 'fuel', 'city', 'province', 'price (PLN)'],\n",
      "      dtype='object')\n",
      "(3104, 10)\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "df = pd.read_csv('Car_Prices.csv')\n",
    "\n",
    "# Get information about data\n",
    "print(df)\n",
    "print(df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     car brand   model  generation_name  year  mileage  vol_engine      fuel  \\\n",
      "0         opel   combo       gen-d-2011  2015   139568        1248    Diesel   \n",
      "1         opel   combo       gen-d-2011  2018    31991        1499    Diesel   \n",
      "2         opel   combo       gen-d-2011  2015   278437        1598    Diesel   \n",
      "3         opel   combo       gen-d-2011  2016    47600        1248    Diesel   \n",
      "4         opel   combo       gen-d-2011  2014   103000        1400       CNG   \n",
      "...        ...     ...              ...   ...      ...         ...       ...   \n",
      "3099      opel  vectra  gen-c-2002-2008  2007   248000        1796  Gasoline   \n",
      "3100      opel  vectra  gen-c-2002-2008  2003   263000        1796       LPG   \n",
      "3101      opel  vectra  gen-c-2002-2008  2008   200000        1796  Gasoline   \n",
      "3102      opel  vectra  gen-c-2002-2008  2005   148266        1910    Diesel   \n",
      "3103      opel  vectra  gen-c-2002-2008  2007   182000        1796  Gasoline   \n",
      "\n",
      "                 city       province  \n",
      "0               Janki    Mazowieckie  \n",
      "1            Katowice        Śląskie  \n",
      "2               Brzeg       Opolskie  \n",
      "3           Korfantów       Opolskie  \n",
      "4     Tarnowskie Góry        Śląskie  \n",
      "...               ...            ...  \n",
      "3099         Oleśnica   Dolnośląskie  \n",
      "3100         Swarzędz  Wielkopolskie  \n",
      "3101         Oleśnica   Dolnośląskie  \n",
      "3102  Czarna Dąbrówka      Pomorskie  \n",
      "3103         Jarosław   Podkarpackie  \n",
      "\n",
      "[3104 rows x 9 columns]\n",
      "0       35900\n",
      "1       78501\n",
      "2       27000\n",
      "3       30800\n",
      "4       35900\n",
      "        ...  \n",
      "3099    13900\n",
      "3100     7999\n",
      "3101    14900\n",
      "3102    13000\n",
      "3103    14900\n",
      "Name: price (PLN), Length: 3104, dtype: int64\n",
      "0        9334.00\n",
      "1       20410.26\n",
      "2        7020.00\n",
      "3        8008.00\n",
      "4        9334.00\n",
      "          ...   \n",
      "3099     3614.00\n",
      "3100     2079.74\n",
      "3101     3874.00\n",
      "3102     3380.00\n",
      "3103     3874.00\n",
      "Name: price (USD), Length: 3104, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# When and why to do Train_Test_Split and do it :D\n",
    "\n",
    "# Think what are the inputs and what is the output, what data we need for model training and what operation should we do on data\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "print(X)\n",
    "print(y)\n",
    "\n",
    "# y is now Series (basically Dataframe with one column), not real Dataframe, this mean that u can and have to use different operations\n",
    "y = y * 0.26\n",
    "y.name = \"price (USD)\"\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RSYBixEhlWeh"
   },
   "source": [
    "## Encoding Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'combo': {'gen-d-2011'}, 'vectra': {'gen-c-2002-2008'}, 'agila': {'gen-b-2008'}, 'astra': {'gen-h-2004-2013'}, 'insignia': {'gen-a-2008-2017'}}\n",
      "       model  year  mileage  vol_engine\n",
      "0      combo  2015   139568        1248\n",
      "1      combo  2018    31991        1499\n",
      "2      combo  2015   278437        1598\n",
      "3      combo  2016    47600        1248\n",
      "4      combo  2014   103000        1400\n",
      "...      ...   ...      ...         ...\n",
      "3099  vectra  2007   248000        1796\n",
      "3100  vectra  2003   263000        1796\n",
      "3101  vectra  2008   200000        1796\n",
      "3102  vectra  2005   148266        1910\n",
      "3103  vectra  2007   182000        1796\n",
      "\n",
      "[3104 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "\n",
    "# Iterate through the rows of the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    model = row['model']\n",
    "    generation_name = row['generation_name']\n",
    "    \n",
    "    # Add generation name to the model's set\n",
    "    if model not in models:\n",
    "        models[model] = set()\n",
    "    models[model].add(generation_name)\n",
    "\n",
    "# Check models with more than one generation name\n",
    "for model, generations in models.items():\n",
    "    if len(generations) > 1:\n",
    "        print(f\"Model '{model}' has multiple generations: {generations}\")\n",
    "\n",
    "print(models)\n",
    "\n",
    "# That means we dont even need generation_name, because it is everytime with the same model\n",
    "# delete brand, city, province, generation_name \n",
    "# delete fuel, just u will easier get the OneHotEncoding\n",
    "X = X.iloc[:, [1, 3, 4, 5]]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       model  year  mileage  vol_engine\n",
      "0      combo  2015   139568        1248\n",
      "1      combo  2018    31991        1499\n",
      "2      combo  2015   278437        1598\n",
      "3      combo  2016    47600        1248\n",
      "4      combo  2014   103000        1400\n",
      "...      ...   ...      ...         ...\n",
      "3099  vectra  2007   248000        1796\n",
      "3100  vectra  2003   263000        1796\n",
      "3101  vectra  2008   200000        1796\n",
      "3102  vectra  2005   148266        1910\n",
      "3103  vectra  2007   182000        1796\n",
      "\n",
      "[3104 rows x 4 columns]\n",
      "[[     0      0      1 ...   2015 139568   1248]\n",
      " [     0      0      1 ...   2018  31991   1499]\n",
      " [     0      0      1 ...   2015 278437   1598]\n",
      " ...\n",
      " [     0      0      0 ...   2008 200000   1796]\n",
      " [     0      0      0 ...   2005 148266   1910]\n",
      " [     0      0      0 ...   2007 182000   1796]]\n",
      "[     0      0      1      0      0   2015 139568   1248]\n",
      "[     0      0      0      0      1   2005 149000   1796]\n",
      "[     1      0      0      0      0   2008 142353   1248]\n"
     ]
    }
   ],
   "source": [
    "# Attention, run this cell only once or it will again OneHotEncode your dataset\n",
    "print(X)\n",
    "\n",
    "# encode model and fuel\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[('encoder', OneHotEncoder(), [0])], \n",
    "    remainder='passthrough'  # Keep the rest of the columns as is\n",
    ")\n",
    "\n",
    "X = np.array(ct.fit_transform(X))\n",
    "X = X.astype(int)\n",
    "\n",
    "print(X)\n",
    "print(X[0])\n",
    "print(X[80])\n",
    "print(X[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJqsCbIzlTYR"
   },
   "source": [
    "# Training the Multiple Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here video about How Linear Regression Models work\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mbc-OGh_mwA3"
   },
   "source": [
    "# Testing the Model with Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(776,)\n",
      "(776, 8)\n",
      "(776,)\n",
      "[10104.97  6610.8   3931.07 12694.94  3750.06  1826.45 12000.05  4744.46\n",
      "  2492.67  3232.08  6983.88  2681.49  9931.24  2518.48  2949.6   4878.54\n",
      "  9620.26  6970.09 13397.    6901.67  2349.72  5675.28  4144.4   4060.04\n",
      "  7598.1   8950.32 -1923.24  4894.07 11741.24  1923.44  9151.77  4339.64\n",
      "  5364.54  4190.32  7555.66  5622.39  7327.97  3851.6   2822.93  4808.95\n",
      " 11159.68  4634.04  4634.04  6598.45  1950.7  12393.33  6800.17  3997.43\n",
      "  7235.83  3531.58  7868.23  2730.62  3380.05  9391.46  1950.7   8537.53\n",
      "  5356.9   2457.52  2325.61  4412.83  3163.25  4499.13  1997.96  9526.28\n",
      "  1871.23  2102.8   9248.12  2876.12   549.41   268.95 11619.07  4504.37\n",
      "  3950.97  2339.89  4715.99  5174.36   467.91  3889.96  3267.71  4394.26\n",
      " 11054.73 11275.45  3196.85 10871.81 10827.61  4388.8   7702.09  9693.06\n",
      "  7195.11  3914.66 11520.31 10236.77 11728.04  5364.54  4512.62  2263.6\n",
      "   874.59  5981.23  7170.08 10187.56  2259.95  3049.63  9531.56  5702.11\n",
      "  3837.03  3623.27  6064.09  2985.11  9299.75  3600.91  9325.55  3037.72\n",
      "  2752.48  4967.04  6689.63  4477.8   5142.6  10337.44  7598.1   3647.47\n",
      "  7309.04 10793.2   3669.9   5841.39  4095.72  4905.71  9599.02  4449.15\n",
      "  8261.09  6757.49  7646.68  8698.36  3848.95  7696.14  8142.2   3666.11\n",
      " 10449.08  1579.05  2179.53  2139.75  7517.92  2234.59  8712.9   3939.86\n",
      "  1317.2   6707.42  7765.47  3165.77  5627.53  9771.96  3146.84  5087.93\n",
      "  2876.36  6972.57  6983.85  7302.15  9771.96   335.98 10820.26  3835.07\n",
      "  6862.92  3165.77  5024.58  7113.41  1499.16  5682.62  3844.87  4271.42\n",
      "  4832.15  9928.07 11600.62 10272.14  4091.43 10542.    5462.65   150.23\n",
      "  2322.02  1955.33  1156.93 11344.95  7309.04  4282.6   4640.96  2942.72\n",
      "  3887.79  4476.49 10454.25  4044.63  3661.22  9693.06 10695.15  4524.37\n",
      " 12275.76  3069.42  4183.47 11875.93  5132.03 13239.16  5337.55  4483.26\n",
      "  6605.78  6798.28 10210.96  2064.08  3699.07   485.95  8897.18  2795.99\n",
      " 10529.46  8817.98  2317.18  8549.57  4260.89  3520.1   3851.6   7553.04\n",
      " 10806.96  2745.71  8391.28 12104.77  7799.4   2523.2   5994.31  7708.14\n",
      "  6675.79  6427.25  3860.08  2699.77  7061.28  2539.08  2269.96  2810.41\n",
      "  9140.08  5027.43  5391.15  9334.73   693.3  10780.43 11948.62  4834.72\n",
      "  8568.91  -138.83 12297.67 10399.19  9468.36  9138.01  3293.09  1127.52\n",
      "  6604.02  3538.04  7646.68  2500.21  3730.54  6543.26  3637.9   5529.09\n",
      "  3843.67   963.43  5032.24  -352.01  9606.    4809.05  7384.03  5242.15\n",
      "  4705.37  3309.    2330.94  3887.79  7479.38  3538.04  6421.01  1631.65\n",
      "   436.94  6760.37  4868.71  4504.37  9836.88 10372.82  5359.63  7456.66\n",
      "  1821.23  2188.13  6909.87  6902.64  7514.2   3754.99  8217.51 10013.78\n",
      "  6279.49  4078.99  6185.51  8088.46  4317.35 10871.81  3051.17  8922.8\n",
      "  9654.98  3504.72  1631.65  7496.58  2118.57  1196.34  3628.25  7721.57\n",
      "  4271.42   436.94  2399.6   2352.99  3306.85  4657.75 12770.14  1587.65\n",
      "  5536.99  1986.83  3006.38  2138.24  1997.96  3849.46  3743.68  3449.31\n",
      " 11575.23  8228.06   794.82   968.25  4090.65  7018.67  3672.24  7445.73\n",
      " 10137.66 10454.25  1654.01  9322.45  5473.9   9138.01  8060.93  4214.97\n",
      "  9693.06  9720.56  -689.41  3110.36  3601.07  5884.11  8518.6  11040.96\n",
      "  4600.06  6432.12  6306.35  1684.35  7376.19  3931.42  7008.63  1151.14\n",
      "  3037.67  2411.06  1654.01  2982.73  4851.58  2225.67 13397.    5124.41\n",
      "   712.15  9840.    6101.49  2081.01  4627.73 10755.7   8812.82 11355.07\n",
      " 12865.34  1352.38  1730.46  1260.3   1986.83  4672.82  3546.01  5014.29\n",
      "  4808.95  9254.12  4490.02  2745.71  8073.93  8491.84  8184.81  7285.36\n",
      "  9633.53 12325.76  1904.42  3201.9   7434.65  1053.53  2369.03  2025.66\n",
      "  4042.04  1477.21 10495.54  3826.47  4826.12  4297.9  11655.2   4156.64\n",
      " 10989.34  1799.29  3507.37  9303.18  7014.82  7479.85  8709.59  2409.34\n",
      "  7506.91  7571.06 12123.2   6543.39  9972.49 12437.13  3377.4   8844.48\n",
      " 10871.81  2550.92 10271.3  11834.14 12134.49  3867.76  1964.46  3063.73\n",
      "  2824.06  7863.87  8422.25  2276.86  4435.55  2661.56  6773.22  4586.08\n",
      "  7986.94  3534.41  6724.62  1272.11  7872.24  7115.37  7285.36  8294.93\n",
      "  5761.76  8848.95  6818.68  1522.45  7646.68 12171.95 12493.05  7217.39\n",
      "  8945.3   8942.87  6323.15  9700.    1698.64  3756.73 10123.9   3482.\n",
      "  3192.78  3137.1   4396.61 10210.34  4577.96  5250.58  3843.67  2147.02\n",
      "  4118.61  5777.47  5732.69  2152.   10385.42  3554.27  3629.12  8325.9\n",
      "  5343.13  5768.24  1155.05  3233.75  3881.45 13245.08  4015.62  2337.65\n",
      "  3158.53  2298.25  5887.18 11770.48  1783.36  6255.57  5827.63  4647.18\n",
      "  9427.06  7598.1   4022.26 10855.71  2999.05  6847.    9788.38  4787.39\n",
      "  4066.55 10177.81  6717.16   959.64  3923.45  6983.85  2263.6   3716.63\n",
      " 11962.34 12865.34  2683.34 10572.43  9482.12  5604.95  7950.81  9835.1\n",
      "  9377.17  4877.87 11223.27  2768.76  7384.03  4078.99  3953.62  4306.16\n",
      "  7048.86  5411.96  1101.92  4786.05  3642.37  4116.15  2298.25 12415.43\n",
      "  7355.5   3426.95  1659.47  3476.67  4519.16  7584.33  6116.68 12646.26\n",
      "   150.23 11526.16  4289.77 10787.35  1516.01  4011.25  3559.7   4240.03\n",
      "  9985.1   9906.41  7514.2  10724.37  4478.21  2977.35  7928.45  6956.33\n",
      "  1752.83   693.3   6570.92  8026.15  1642.4  11622.51  1634.11  7679.54\n",
      " 11962.34  1519.18 10739.29 12104.77  9067.87  2568.56  1130.86   943.42\n",
      "  4187.71 11035.8   3601.07 10757.07  4547.52  2409.34  4848.14  4312.05\n",
      "   963.43  4692.88  3950.97  2890.48  2161.66  3023.35  1383.7   2409.34\n",
      "  4504.37  8107.39  7599.07  5955.45  8029.27  3496.12  4153.5   6869.93\n",
      "  8317.29 10363.06 12905.41  5339.92  3889.78  6433.27 10883.24 12411.11\n",
      "  2308.85  8771.53  7612.7   3198.82  4971.15  1317.2   7950.81  2438.21\n",
      "  5002.99  1881.34  8678.61  5035.86  1521.53  2517.95  1576.59  3412.68\n",
      "  8049.47  6632.36  4256.75  8563.74 11531.82  6387.64 10372.82  3036.44\n",
      "  4339.64   277.55  2806.93 11177.57 10354.67  9059.21  9636.97  2509.22\n",
      "  8549.57  3915.29  3115.52 12713.93 12100.84  9140.08  9830.26 12329.74\n",
      "   588.    1264.68  7786.55  4237.33  3914.66  3429.65  3882.15  5875.55\n",
      "  7267.75  4715.99  5089.01  4172.18  3784.83  1925.48  3730.04  2587.15\n",
      "  5214.62  5691.92  5024.58  9628.37  8577.86  5231.51  7413.99  6869.93\n",
      " 10779.43  8489.35 -1923.24  1499.16  2750.32  9531.56  3772.09 11659.64\n",
      " 10457.73  3440.14  3835.07  2097.29  2442.43  4201.39  2939.32  1753.01\n",
      "  2599.53 10096.37  3259.2   3931.42  7231.62  1890.48  8997.43  3997.43\n",
      " 10996.46  1946.91  3110.58  3796.13  9954.83  1877.65  4219.81  9059.21\n",
      "  1831.47  6615.65  4117.55  7529.27  2933.28  2890.48  2825.6   9661.54\n",
      " 10380.26  2097.29  7784.68  1802.06 10206.48  5255.83  9774.83  8757.76\n",
      "  4240.03  5369.23  7046.2   2228.23  2678.84  7991.06 11242.27  7237.38\n",
      "  3701.95  9531.56  4905.71  2476.22  2557.11 10187.56  1579.4   4646.3\n",
      "  4230.12  4400.36 10271.45  6832.44  1155.05  -452.68   796.86  6964.93\n",
      "  9684.28  6514.71  4267.82  1567.6   3869.38  9832.09  3394.6  11127.71\n",
      "  6847.    3672.24  5403.31  3849.77  1751.97   794.82  3708.37  4720.75\n",
      "  7937.05   558.01  7171.4   9624.94  4752.14  8404.07  4524.37  3661.92\n",
      "  1749.66  4446.5   7630.79  9504.49  5164.72  1368.46  8656.25  7707.07\n",
      "   693.3   1796.91  4110.01  5080.01  3504.72  2014.71  1147.02  3583.2 ]\n",
      "[[10104.97 12194.  ]\n",
      " [ 6610.8   7279.74]\n",
      " [ 3931.07  3978.  ]\n",
      " ...\n",
      " [ 2014.71  1819.74]\n",
      " [ 1147.02  2834.  ]\n",
      " [ 3583.2   3614.  ]]\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "y_pred = reg.predict(X_test)\n",
    "print(y_pred.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# precision\n",
    "np.set_printoptions(precision=2)\n",
    "print(y_pred)\n",
    "\n",
    "# Toto zobrazenie urobit asi inak\n",
    "# np.concatenate\n",
    "y_test = np.array(y_test)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred), 1), y_test.reshape(len(y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJ0luePmnGQn"
   },
   "source": [
    "# Evaluation of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.862195570062051"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
